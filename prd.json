{
  "project": "cantena-product-pipeline",
  "branchName": "ralph/product-pipeline",
  "description": "The product layer for Cantena — PDF ingestion, VLM-based drawing analysis, FastAPI backend, and Next.js frontend. Upload a construction floor plan PDF, get a conceptual budget in under 60 seconds. Pipeline: PDF → images → VLM analysis → BuildingModel → CostEngine → CostEstimate → UI display.",
  "userStories": [
    {
      "id": "US-101",
      "title": "Frontend scaffolding: Next.js project with Tailwind",
      "description": "As a developer, I want a properly structured Next.js frontend project so that subsequent UI stories have a foundation to build on.",
      "acceptanceCriteria": [
        "frontend/ directory uses existing Next.js 14+ App Router project with TypeScript strict mode",
        "Tailwind CSS configured and working",
        "ESLint and TypeScript strict mode configured in tsconfig.json",
        "Landing page remains at / (out of scope) — product UI lives under /analyze route",
        "frontend/src/app/analyze/page.tsx exists as the entry point for product analysis",
        "package.json has scripts: dev, build, lint, typecheck (tsc --noEmit)",
        "frontend/lib/types.ts defines TypeScript interfaces matching Python CostEstimate, CostRange, DivisionCost, Assumption, BuildingSummary models from PRD 1",
        "frontend/lib/api.ts defines typed fetch wrapper: analyzePlan(file, location) -> Promise<CostEstimate> that POSTs to /api/analyze (stubbed with TODO)",
        "npm run typecheck passes",
        "npm run lint passes",
        "Typecheck passes"
      ],
      "priority": 1,
      "passes": true,
      "notes": "Keep it simple. No component libraries, no state management libraries. Just Next.js, Tailwind, and TypeScript. The types.ts file is critical — it's the contract between frontend and backend. Generate it to match the Pydantic models exactly. Do not recreate the landing page. Product work should sit alongside it via routing (e.g. /analyze)."
    },
    {
      "id": "US-102",
      "title": "PDF processing service: PDF to high-res images",
      "description": "As a developer, I want a service that takes a PDF file and produces high-resolution PNG images of each page so that the VLM can analyze construction drawings.",
      "acceptanceCriteria": [
        "cantena/services/pdf_processor.py defines PdfProcessor class",
        "PdfProcessor.process(pdf_path) -> PdfProcessingResult converts PDF to images",
        "PdfProcessingResult contains: pages (list[PageResult]), page_count (int), file_size_bytes (int)",
        "PageResult contains: page_number, image_path, width_px, height_px, text_content, title_block_text (str | None)",
        "Images rendered at 200 DPI",
        "PyMuPDF (fitz) used for both text extraction and image rendering",
        "Temporary image files written to configurable output directory (default: system temp dir)",
        "PdfProcessor.cleanup(result) method deletes temporary image files",
        "Tests: process test PDF, text extraction, cleanup deletes files, empty PDF handling, non-PDF error handling",
        "Add PyMuPDF and Pillow to pyproject.toml dependencies",
        "mypy --strict passes",
        "Typecheck passes"
      ],
      "priority": 2,
      "passes": true,
      "notes": "200 DPI is intentional — higher DPI means more VLM tokens and slower processing. Title block text extraction (bottom-right quadrant) is a cheap heuristic for sheet name, scale, and project info without VLM cost. Use PyMuPDF for everything — no need for Poppler/pdf2image."
    },
    {
      "id": "US-103",
      "title": "VLM analysis service: image to BuildingModel",
      "description": "As a developer, I want a service that sends a construction drawing image to a VLM API and gets back a structured BuildingModel so that the cost engine can produce an estimate.",
      "acceptanceCriteria": [
        "cantena/services/vlm_analyzer.py defines VlmAnalyzer class with API key and model name in constructor",
        "VlmAnalyzer.analyze(image_path, context) -> VlmAnalysisResult sends image to Anthropic Messages API with vision",
        "AnalysisContext model with: project_name, location, additional_notes (all optional)",
        "VlmAnalysisResult model with: building_model, raw_response, reasoning, warnings",
        "System prompt implements multi-pass approach in single API call: describe, state confidence, flag guesses, output JSON matching BuildingModel schema",
        "Response parsing: extract JSON, validate against BuildingModel, retry on malformed response (max 1 retry)",
        "Missing fields get LOW confidence defaults",
        "All tests mock Anthropic API — no real API calls",
        "Tests: well-formed response parsing, malformed response retry, missing field defaults, AnalysisContext passthrough",
        "anthropic SDK added to pyproject.toml",
        "mypy --strict passes",
        "Typecheck passes"
      ],
      "priority": 3,
      "passes": true,
      "notes": "CRITICAL: All tests must mock the Anthropic API. Never make real API calls in automated tests. System prompt is key IP — put it in a separate constant or file. Single-call approach saves cost and latency. Ask VLM to think aloud before outputting JSON for accuracy."
    },
    {
      "id": "US-104",
      "title": "Analysis pipeline: orchestrate PDF to VLM to CostEngine",
      "description": "As a developer, I want a pipeline service that orchestrates the full analysis flow so that the API endpoint has a single entry point.",
      "acceptanceCriteria": [
        "cantena/services/pipeline.py defines AnalysisPipeline class taking PdfProcessor, VlmAnalyzer, and CostEngine in constructor",
        "AnalysisPipeline.analyze(pdf_path, project_name, location) -> PipelineResult",
        "PipelineResult model with: estimate, analysis, processing_time_seconds, pages_analyzed",
        "Pipeline steps: process PDF, select best page, run VLM, run cost engine, cleanup temps, return result",
        "Custom exceptions in cantena/exceptions.py: CantenaError base, PdfProcessingError, VlmAnalysisError, CostEstimationError",
        "Tests: happy path with mocks, PDF error wrapping, VLM error wrapping, cost engine error wrapping, cleanup called on failure",
        "mypy --strict passes",
        "Typecheck passes"
      ],
      "priority": 4,
      "passes": true,
      "notes": "Pipeline is intentionally simple for MVP — single page analysis only. Page selection heuristic: first architectural floor plan page (largest page, or page with 'floor plan' in title block, or page 1). Multi-page analysis is Phase 1 work."
    },
    {
      "id": "US-105",
      "title": "FastAPI backend: /api/analyze endpoint",
      "description": "As a developer, I want a FastAPI application with an analyze endpoint so that the frontend can upload a PDF and get back a cost estimate.",
      "acceptanceCriteria": [
        "cantena/api/app.py defines a FastAPI application with create_app factory",
        "POST /api/analyze accepts multipart form data: file, project_name, city, state",
        "Endpoint saves upload to temp dir, runs AnalysisPipeline, returns PipelineResult as JSON",
        "Response includes full CostEstimate with summary_dict and export_dict",
        "Error responses: 400 invalid file type, 422 missing fields, 500 pipeline errors",
        "GET /api/health returns {status: 'ok', version: '0.1.0'}",
        "CORS middleware allows localhost:3000",
        "cantena/api/deps.py handles dependency injection",
        "Tests with FastAPI TestClient: health 200, analyze with test PDF 200 (mock VLM), non-PDF 400, missing fields 422, pipeline error 500",
        "Add fastapi, uvicorn, python-multipart to pyproject.toml",
        "mypy --strict passes",
        "Typecheck passes"
      ],
      "priority": 5,
      "passes": true,
      "notes": "create_app factory pattern allows tests to inject mocked dependencies without env vars. Keep API surface minimal for MVP: one endpoint that does everything. summary_dict/export_dict from PRD 1 US-008 included in response so frontend doesn't reformat."
    },
    {
      "id": "US-106",
      "title": "Upload UI: PDF upload with location input",
      "description": "As a PM trying the demo, I want to upload a floor plan PDF and enter a project location so that the system can analyze my drawing.",
      "acceptanceCriteria": [
        "frontend/src/app/analyze/page.tsx is the main product page with upload interface (landing remains at /)",
        "UI has: drag-and-drop zone for PDF, project name input, city input, state dropdown, Analyze button",
        "File validation: only .pdf, max 50MB, error for invalid files",
        "Loading state with staged progress messages: Processing PDF, Analyzing drawing, Generating estimate",
        "Error state with descriptive message and retry option",
        "On success, renders results view on same page",
        "Responsive design for desktop and tablet",
        "Uses api.ts fetch wrapper from US-101",
        "Clean professional design — muted blues and grays, clear typography, generous whitespace",
        "npm run typecheck passes",
        "npm run lint passes",
        "Typecheck passes",
        "Verify in browser using dev-browser skill"
      ],
      "priority": 6,
      "passes": true,
      "notes": "Loading states are important — processing takes 15-30 seconds. Staged progress messages build anticipation and trust. Keep form simple: project name + location + file. Don't add fields the VLM extracts."
    },
    {
      "id": "US-107",
      "title": "Results UI: budget display with division breakdown",
      "description": "As a PM reviewing an estimate, I want to see the conceptual budget with a clear breakdown by CSI division so that I can quickly assess whether the numbers make sense.",
      "acceptanceCriteria": [
        "Results section shows after successful analysis on /analyze page below upload form",
        "Header: project name, building summary, total cost (expected prominent, range smaller), cost per SF",
        "Division breakdown table: CSI division number, name, expected cost, percent of total, cost range — sorted by cost descending, top 3 highlighted",
        "Assumptions section: collapsible panel with parameter, assumed value, reasoning, confidence badge (green HIGH, yellow MEDIUM, red LOW)",
        "AI reasoning section: collapsible panel showing VLM observations",
        "Metadata footer: timestamp, engine version, estimation method, location factor",
        "All monetary values use formatting from PRD 1",
        "npm run typecheck passes",
        "npm run lint passes",
        "Typecheck passes",
        "Verify in browser using dev-browser skill"
      ],
      "priority": 7,
      "passes": true,
      "notes": "Division breakdown sorted by cost (not division number) helps PMs see budget drivers instantly. Assumptions panel is the trust builder. AI reasoning section lets PMs verify VLM didn't hallucinate."
    },
    {
      "id": "US-108",
      "title": "Parameter override: backend estimate endpoint",
      "description": "As a developer, I want a POST /api/estimate endpoint that accepts a BuildingModel and returns a CostEstimate so that the frontend can recalculate estimates when PMs correct parameters.",
      "acceptanceCriteria": [
        "POST /api/estimate endpoint accepts BuildingModel JSON body and returns CostEstimate",
        "No PDF processing, no VLM — goes straight to cost engine",
        "Tests: valid BuildingModel returns 200, invalid data returns 422",
        "mypy --strict passes",
        "Typecheck passes"
      ],
      "priority": 8,
      "passes": false,
      "notes": "This endpoint is also useful standalone — a PM who knows their building parameters can skip VLM entirely. Split from the UI story to keep each iteration small."
    },
    {
      "id": "US-109",
      "title": "Parameter override UI: editable fields with recalculate",
      "description": "As a PM, I want to correct any parameter the AI extracted from my drawing so that I can fix mistakes and see the budget update immediately.",
      "acceptanceCriteria": [
        "Building parameters section between header and division breakdown shows extracted parameters as editable fields",
        "Editable fields: building type dropdown, gross SF, stories, story height, structural system dropdown, exterior wall dropdown, location city/state",
        "Each field shows confidence badge (HIGH/MEDIUM/LOW)",
        "Changing any parameter shows a Recalculate button (not auto-submit)",
        "Recalculate sends corrected BuildingModel to POST /api/estimate",
        "Budget display updates with new estimate",
        "Original estimate preserved — user can toggle between AI estimate and adjusted estimate",
        "npm run typecheck passes",
        "npm run lint passes",
        "Typecheck passes",
        "Verify in browser using dev-browser skill"
      ],
      "priority": 9,
      "passes": false,
      "notes": "This is the human-in-the-loop feature. Deliberate Recalculate button (vs auto-update) because construction PMs want control. Depends on US-108 for the /api/estimate endpoint."
    },
    {
      "id": "US-110",
      "title": "Demo polish: sample results and error recovery",
      "description": "As a developer demoing to PMs, I want sample/cached results and graceful error handling so that the demo doesn't fail live.",
      "acceptanceCriteria": [
        "GET /api/sample-estimate returns pre-built CostEstimate for realistic project (45K SF 3-story steel office, Baltimore)",
        "Frontend has Try sample estimate button on /analyze that loads sample without PDF upload",
        "If ANTHROPIC_API_KEY not set, /api/analyze returns helpful error suggesting sample estimate",
        "Frontend error boundary: shows 'Something went wrong' with retry instead of blank screen",
        "VLM call has 60-second timeout with descriptive timeout error",
        "All existing tests still pass",
        "npm run typecheck passes",
        "npm run lint passes",
        "Typecheck passes",
        "Verify in browser using dev-browser skill"
      ],
      "priority": 10,
      "passes": false,
      "notes": "Sample estimate is demo insurance — always have a working demo regardless of API availability or network issues. Sample should be realistic: 3-story steel-frame office, 45K SF, curtain wall, Baltimore MD."
    },
    {
      "id": "US-111",
      "title": "Docker Compose for local development",
      "description": "As a developer, I want a single command to start the full stack locally so that anyone on the team can run the complete application.",
      "acceptanceCriteria": [
        "docker-compose.yml at project root with backend (FastAPI) and frontend (Next.js) services",
        "Backend: builds from backend/Dockerfile, port 8000, mounts backend/ for hot reload, passes ANTHROPIC_API_KEY from .env",
        "Frontend: builds from frontend/Dockerfile, port 3000, mounts frontend/ for hot reload, proxies API calls to backend",
        "backend/Dockerfile: Python 3.11 slim, installs from pyproject.toml, runs uvicorn with reload",
        "frontend/Dockerfile: Node 20, installs deps, runs next dev",
        ".env.example with ANTHROPIC_API_KEY placeholder",
        "docker compose up starts both services and they communicate",
        "README.md at project root with overview, prerequisites, setup instructions",
        "Quality gates pass inside backend container",
        "Typecheck passes"
      ],
      "priority": 11,
      "passes": false,
      "notes": "Docker Compose makes onboarding trivial. .env.example pattern is standard and safe. Hot reload on both services for rapid iteration. Keep Dockerfiles simple — no multi-stage builds. Working > optimized for demo stage."
    }
  ]
}
