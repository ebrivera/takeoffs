## Codebase Patterns
- All source files use `from __future__ import annotations`
- Frozen dataclasses for immutable models (`@dataclass(frozen=True)`)
- `StrEnum` for string-based enumerations (not `(str, Enum)`)
- `TYPE_CHECKING` block for expensive imports (fitz, etc.)
- `Point2D` and `BoundingRect` from `cantena.geometry.extractor`
- `WallSegment` and `WallAnalysis` from `cantena.geometry.walls`
- `TextBlock` and `ScaleResult` from `cantena.geometry.scale`
- Union-find clustering for endpoint snapping (O(n²) pairwise, KDTree upgrade path documented)
- mypy runs slow on first invocation — use `--no-incremental` if it hangs
- Use `.venv/bin/ruff` and `.venv/bin/mypy` directly (not `python3 -m`)
- `dataclasses.replace()` for updating frozen dataclass instances (not `dataclasses.asdict()` + constructor)
- Room label matching uses `_ROOM_NAMES` frozenset with longest-first substring matching
- Anthropic `ImageBlockParam` `media_type` requires `Literal["image/jpeg", "image/png", "image/gif", "image/webp"]` — plain `str` fails mypy
- `Path` import goes in `TYPE_CHECKING` block when only used in annotations (ruff TC003)
- `ScaleVerifier` and `ScaleVerificationResult` from `cantena.geometry.scale_verify`
- LLM verification decision logic: ±5% confirmed, ±10% confirmed+warning, >10% keep deterministic+warning
- `VerificationSource` is a `Literal` type alias, not an enum (keeps it simple for dataclass field)
- Register custom pytest marks (e.g., `llm`) in `pyproject.toml` under `[tool.pytest.ini_options]` markers — `--strict-markers` enforces this
- LLM integration tests: `_get_api_key()` helper + `pytest.skip()` for missing API key; catch 429 with `pytest.skip("Rate limited")`

---

## 2026-02-08 - US-371
- What was implemented: Endpoint snapping module `cantena/geometry/snap.py` with `snap_endpoints()` and `snap_to_grid()` functions. Uses union-find clustering to snap wall segment endpoints within a configurable tolerance (default 3.0 pts), replacing each cluster with its centroid. Removes duplicate segments after snapping. Includes `snap_to_grid()` helper for rounding to grid points.
- Files changed:
  - `backend/cantena/geometry/snap.py` — new module: `snap_endpoints(segments, tolerance_pts)`, `snap_to_grid(point, grid_size_pts)`, `_cluster_endpoints()` with union-find, `_reclassify_orientation()`, `_distance()` helper
  - `backend/tests/test_snap.py` — 13 tests: 8 in TestSnapEndpoints (within/outside tolerance, duplicate removal, empty input, exact match, thickness preservation, length recompute, three-way cluster) + 5 in TestSnapToGrid (nearest grid, unchanged, half-round, custom/large grid sizes)
  - `prd.json` — US-371 passes: true
- **Learnings for future iterations:**
  - Unused imports (e.g., `dataclass` if not used in file) trigger ruff F401 — check before committing
  - mypy `--no-incremental` flag needed when mypy hangs on first run
  - Union-find with path compression is simple and effective for endpoint clustering
  - Orientation is reclassified after snapping since endpoint movement can change angle
  - Duplicate detection uses canonical (min, max) pair keys for order-independence
---

## 2026-02-08 - US-351
- What was implemented: Integration test fixtures and smoke tests for first-floor.pdf — conftest.py with `first_floor_pdf` and `first_floor_page` fixtures, ground truth constants, and smoke test file verifying PDF loads, page count, dimensions, and text content.
- Files changed:
  - `backend/tests/integration/__init__.py` — new integration test package
  - `backend/tests/integration/conftest.py` — `first_floor_pdf` fixture (yields fitz.Document, closes on teardown), `first_floor_page` fixture (yields first page), ground truth constants (EXPECTED_SCALE_FACTOR=48.0, EXPECTED_OVERALL_WIDTH_FT=32.0, EXPECTED_OVERALL_DEPTH_FT=16.0, EXPECTED_GROSS_AREA_SF=512.0, EXPECTED_TOTAL_WITH_PORCHES_SF=700.0, EXPECTED_ROOM_COUNT=7)
  - `backend/tests/integration/test_first_floor_smoke.py` — 4 smoke tests: PDF loads, has exactly 1 page, page has non-zero dimensions, page contains text
  - `prd.json` — US-351 passes: true
- **Learnings for future iterations:**
  - `test_pdfs/` is at repo root, not in `backend/` — `Path(__file__).resolve().parents[3]` from `tests/integration/conftest.py` reaches the repo root
  - `Generator` import from `collections.abc` needs to go in `TYPE_CHECKING` block per ruff TC003
  - Empty `if TYPE_CHECKING: pass` blocks trigger ruff TC005 — just remove them if unused
  - Integration test fixtures use `Generator` return type for yield fixtures that need cleanup
---

## 2026-02-08 - US-352
- What was implemented: Integration tests validating VectorExtractor against the real first-floor.pdf — verifies path count (>=50), line/rect stats, bounding box coverage (>=50% width, >=40% height), line width distribution (>=2 distinct widths), stroke color majority, filter_by_region reduction, and rasterized PDF skip fallback.
- Files changed:
  - `backend/tests/integration/test_first_floor_vectors.py` — 8 tests across TestVectorExtraction (7 tests) and TestRasterizedFallback (1 test)
  - `prd.json` — US-352 passes: true
- **Learnings for future iterations:**
  - VectorExtractor on first-floor.pdf extracts hundreds of paths — PDF has rich vector data, not rasterized
  - Line width distribution is logged for debugging wall detection thresholds — useful for US-354 tuning
  - `Counter[float]` typing works cleanly for counting line width occurrences
  - f-strings without placeholders trigger ruff F541 — use plain strings for static text
  - Integration tests with `print()` output need `-s` flag to see during development, but pass without it
---

## 2026-02-08 - US-353
- What was implemented: Integration tests validating ScaleDetector on the real first-floor.pdf, plus a two-step text normalization approach in `detect_from_text` (Unicode canonicalization + tolerant regex parsing). Tests cover text block extraction (>=20 blocks), scale detection from page text (scale_factor ~48.0), all 11 dimension string parses, dimension-based inference attempt, messy format resilience (Unicode quotes, extra whitespace, prime symbols), and correct behavior without API text interpreter.
- Files changed:
  - `backend/cantena/geometry/scale.py` — added `_normalize_scale_text()` function for two-step approach: normalizes Unicode quotes (\u201c/\u201d/\u2033/\u2018/\u2019/\u2032) to ASCII and collapses whitespace before regex matching
  - `backend/tests/integration/test_first_floor_scale.py` — new file: 23 tests across 6 test classes (TestTextBlockExtraction, TestDetectFromText, TestParseDimensionStrings, TestDetectFromDimensions, TestMessyFormatResilience, TestNoApiTextInterpreter)
  - `prd.json` — US-353 passes: true
- **Learnings for future iterations:**
  - Real PDF scale text is `SCALE: 1/4" =1'-0"` (note space before `=`) — existing regex already handles this but normalization makes it more robust
  - `detect_from_dimensions` on this drawing returns scale_factor ~144 (not ~48) because the closest dimension/line pairing is a short annotation line with a dimension value — dimension calibration is a fallback, not primary
  - The PDF has 118 text blocks total — plenty for analysis
  - `_normalize_scale_text` replaces all common Unicode quote variants (\u201c, \u201d, \u2033, \u2018, \u2019, \u2032, \u201e, \u00ab, \u00bb) to ASCII equivalents
  - Two-step approach (normalize → parse) is more resilient than adding more Unicode alternatives to regex character classes
---

## 2026-02-08 - US-354
- What was implemented: Integration tests validating WallDetector on the real first-floor.pdf, plus tuning of WallDetector heuristics to produce accurate results. Tests cover: ≥8 wall segments (got 42), ≥3 H/V each (23 H, 19 V), total wall length 80-250 LF (got 227.5), enclosed area 380-700 SF (got 548.0, +7% error vs 512 SF), wall thickness 3-12" (got 6.2"), and a diagnostic summary.
- Files changed:
  - `backend/tests/integration/test_first_floor_walls.py` — new file: 7 tests across TestWallDetection class (segment count, H/V counts, wall length range, area range, thickness range, diagnostic summary)
  - `backend/cantena/geometry/walls.py` — added `_MIN_WALL_LENGTH_PTS = 36` minimum segment length filter (excludes annotation ticks, dimension leader lines) and `_remove_length_outliers()` IQR-based outlier removal (excludes title block borders)
  - `prd.json` — US-354 passes: true
- **Learnings for future iterations:**
  - Unfiltered WallDetector picked up 238 segments (385 LF, 1771 SF area) — mostly annotation ticks and short marks under 1 ft
  - Two line widths on this drawing: 1.134 pts (dimension/annotation lines) and 1.417 pts (structural walls)
  - Minimum length filter of 36 pts (~2 ft at 1/4" scale) removed 181 out of 238 annotation/tick segments
  - Title block border was a 53.4 ft line at Y=751 spanning full page — IQR method (Q3 + 3*IQR upper bound) correctly identified and removed it
  - Dimension annotation leader lines at Y=86 and Y=684 (1.2 ft each) were also removed by the 36pt minimum length filter
  - Convex hull of wall endpoints gives ~548 SF (7% over expected 512 SF) — includes some porch area but well within ±25% tolerance
  - Wall thickness detection via parallel pair analysis: median 6.2 inches (~10.5 pts gap between parallel wall lines)
  - `pts_to_real_lf(pts, scale)` and `pts_to_real_sf(pts, scale)` from measurement.py are the correct conversion functions for integration tests
---

## 2026-02-08 - US-355
- What was implemented: Integration tests validating full MeasurementService.measure() pipeline on first-floor.pdf — verifies end-to-end measurement (scale detection → wall detection → area/perimeter/wall length computation), plus resilience tests with mocked mangled scale text ensuring graceful degradation.
- Files changed:
  - `backend/tests/integration/test_first_floor_measurement.py` — new file: 9 tests across TestMeasurementPipeline (7 tests) and TestMangledScaleResilience (2 tests)
  - `prd.json` — US-355 passes: true
- **Learnings for future iterations:**
  - MeasurementService.measure() on first-floor.pdf achieves HIGH confidence: scale_factor=48.0, gross_area=548.0 SF (+7% vs 512), perimeter=97.9 LF, wall_length=227.5 LF, 42 walls
  - When text extraction returns empty blocks (mangled text), detect_from_text and detect_from_dimensions both return None → pipeline falls back to estimated scale (factor=96) with LOW confidence, area balloons to ~2192 SF (because scale_factor doubles)
  - `patch.object(ScaleDetector, "extract_text_blocks", return_value=[])` is the cleanest way to simulate text extraction failure without needing a real mangled PDF
  - The pipeline never crashes on missing text — graceful degradation works: result is always returned, confidence degrades to LOW
---

## 2026-02-08 - US-356
- What was implemented: Integration tests validating text and room label extraction from first-floor.pdf — verifies all 9 expected room labels found (case-insensitive with newline normalization), label positions within drawing content area, spatial separation of distinct label blocks, coarse left/right zone mapping, at least 10 dimension text blocks, and title block fields (SCALE, 1/4, A1.2, 1ST FLOOR, AMERICAN FARMHOUSE) in border areas.
- Files changed:
  - `backend/tests/integration/test_first_floor_rooms.py` — new file: 6 tests across 6 test classes (TestRoomLabelExtraction, TestRoomLabelPositions, TestRoomLabelSpatialSeparation, TestCoarseZoneMapping, TestDimensionBlocks, TestTitleBlockFields)
  - `prd.json` — US-356 passes: true
- **Learnings for future iterations:**
  - PyMuPDF text blocks may contain multiple room labels in one block (e.g. "LIVING ROOM\nKITCHEN") — normalize newlines to spaces before label matching
  - "BACK PORCH" appears as "BACK \nPORCH" (split across lines within one text block) — `re.sub(r"\s+", " ", text)` normalization is essential
  - Title block text uses spaced-out characters: "A M E R I C A N  F A R M H O U S E" — collapse with `re.sub(r"\b(\w) (?=\w\b)", r"\1", text)` then normalize remaining whitespace
  - Title block elements spread across page edges: SCALE at lower-left (148, 760), AMERICAN FARMHOUSE at right-center (1161, 363), sheet number at lower-right (1152, 766) — search border areas (right 15% OR bottom 15%) not just lower-right quadrant
  - Spatial separation test must de-duplicate by text block position — labels sharing the same PDF text block (e.g. LIVING ROOM + KITCHEN at distance 0) are acceptable for open-plan rooms
  - 21 dimension text blocks found, well above the 10 minimum threshold
  - All 9 room labels found, distributed: left half (4): LIVING ROOM, KITCHEN, FRONT PORCH, LAUNDRY; right half (5): DINING, BACK PORCH, UTILITY, WC, COATS
---

## 2026-02-08 - US-357
- What was implemented: Geometry accuracy report generation and minimum threshold assertion tests — capstone integration test that runs the full pipeline on first-floor.pdf, writes a comprehensive markdown report to test_results/first-floor-geometry-report.md, and verifies minimum accuracy thresholds (scale ±10%, area ±30%, ≥6 room labels).
- Files changed:
  - `backend/tests/integration/test_first_floor_report.py` — new file: TestReportGeneration (1 test: generates full report with Drawing Info, Measurement Results, Text Extraction, Confidence Assessment, Scale Detection Path, Known Limitations, and Recommendations sections), TestMinimumThresholds (3 tests: scale factor ±10%, gross area ±30%, ≥6 room labels)
  - `test_results/first-floor-geometry-report.md` — generated report file (created by test)
  - `prd.json` — US-357 passes: true
- **Learnings for future iterations:**
  - Report results: Scale factor 48.0 (exact match), gross area 548.0 SF (+7.0% vs 512 SF expected), perimeter 97.9 LF (+2.0% vs 96 LF expected), 42 walls (23H, 19V), wall thickness ~6.2"
  - All confidence components rated HIGH: scale detection (deterministic text normalization/parsing), wall detection (≥8 segments + outer boundary), text extraction (9/9 room labels)
  - `datetime.UTC` alias required (not `timezone.utc`) per ruff UP017
  - Report-generation test always passes (diagnostic tool) but must assert file creation
  - Threshold tests are separate from the report test to clearly distinguish pass/fail assertions from diagnostic output
---

## 2026-02-08 - US-372
- What was implemented: Room polygon reconstruction via Shapely polygonize in `cantena/geometry/rooms.py`. `RoomDetector` class with `detect_rooms()` method that snaps endpoints (US-371), extends segments by 1pt, converts to Shapely LineStrings, unions linework, calls `polygonize()`, filters tiny artifacts (<100 sq pts) and page boundary polygons (>80% page area), and falls back to convex hull if polygonize produces 0 rooms. Includes `DetectedRoom` and `RoomAnalysis` frozen dataclasses with area/perimeter conversion to SF/LF when scale provided.
- Files changed:
  - `backend/cantena/geometry/rooms.py` — new module: `RoomDetector.detect_rooms()`, `DetectedRoom` (frozen dataclass), `RoomAnalysis` (frozen dataclass), `_extend_segment()`, `_polygon_to_detected_room()`, `_convex_hull_fallback()`
  - `backend/tests/test_rooms.py` — 18 tests across 8 test classes: TestDetectRoomsSingleRectangle (4), TestDetectRoomsTwoAdjacent (2), TestSmallGapsSnapped (1), TestNonClosingFallback (1), TestTinyArtifactsFiltered (1), TestEmptyInput (2), TestPageBoundaryFilter (1), TestRoomAnalysisModel (6)
  - `prd.json` — US-372 passes: true
- **Learnings for future iterations:**
  - Shapely's `polygonize()` requires exact endpoint equality — snapping (US-371) + segment extension (1pt) ensures overlapping linework for polygon formation
  - Deferred Shapely imports inside methods (`from shapely.geometry import ...`) to avoid circular imports and keep TYPE_CHECKING clean
  - Area conversion: `area_sf = area_pts / (72^2) * scale_factor^2 / 144`; Perimeter: `perimeter_lf = perimeter_pts / 72 * scale_factor / 12`
  - `_convex_hull_fallback()` returns `polygonize_success=False` so downstream code can distinguish accurate room-based area from approximate hull area
  - `unary_union(lines)` before `polygonize()` is essential — it nodes intersections so polygonize can find closed loops
---

## 2026-02-08 - US-373
- What was implemented: Room label matching in `cantena/geometry/rooms.py` — `RoomDetector.label_rooms()` method that associates text labels with detected room polygons. Uses a curated `_ROOM_NAMES` frozenset (37 common room names), case-insensitive matching with whitespace normalization, Shapely polygon containment checks, nearest-centroid fallback within 50pts, and duplicate label indexing (e.g. BEDROOM 1, BEDROOM 2). Uses `dataclasses.replace()` to create new frozen DetectedRoom instances with labels.
- Files changed:
  - `backend/cantena/geometry/rooms.py` — added `_ROOM_NAMES` frozenset, `_MAX_LABEL_DISTANCE_PTS` constant, `_normalize_label_text()`, `_match_room_name()` helpers, `RoomDetector.label_rooms()` method; added `re` and `replace` imports; added `TextBlock` to TYPE_CHECKING block
  - `backend/tests/test_room_labels.py` — new file: 9 tests across 8 test classes (TestLabelInsidePolygon, TestLabelOutsideAssignsNearest, TestNonRoomTextIgnored, TestUnlabeledRoomsRemainNone, TestDuplicateNamesGetIndexed, TestCaseInsensitiveMatching, TestEmptyInputs, TestSubstringMatch)
  - `prd.json` — US-373 passes: true
- **Learnings for future iterations:**
  - Shapely `poly.contains(pt)` returns False for points exactly on boundary — use `poly.boundary.distance(pt) < 1.0` as fallback
  - Ruff SIM102 requires combining nested `if` statements with `and` instead of nesting
  - For "outside label assigns to nearest" tests, room centroid must be within 50pts of the outside label position — large rooms have centroids far from edges
  - Shapely coordinate sequences yield `tuple[float, ...]` not `tuple[float, float]` — must cast explicitly for mypy --strict
  - `dataclasses.replace()` is the clean way to update frozen dataclass fields
---

## 2026-02-08 - US-374
- What was implemented: LLM-assisted geometry interpretation service in `cantena/services/llm_geometry_interpreter.py`. `LlmGeometryInterpreter` class that sends extracted geometry data (rooms, measurements, text blocks) and optionally a PDF page image to Claude for semantic analysis. Returns `LlmInterpretation` with building_type, structural_system, per-room confirmed labels/types, special conditions, measurement flags, and confidence notes. Gracefully falls back to default UNKNOWN interpretation on any API error (timeout, 429, malformed response).
- Files changed:
  - `backend/cantena/services/llm_geometry_interpreter.py` — new module: `LlmGeometryInterpreter.interpret()`, `GeometrySummary`, `RoomSummary`, `LlmInterpretation`, `LlmRoomInterpretation` (all frozen dataclasses), `_serialize_geometry_summary()`, `_extract_json()`, `_build_interpretation()` helpers
  - `backend/tests/test_llm_geometry_interpreter.py` — 17 tests across 7 test classes: TestWellFormedResponse (4), TestMalformedResponse (3), TestTimeoutFallback (3), TestGeometrySummarySerialization (3), TestVisionInput (3), TestDefaultInterpretation (1)
  - `prd.json` — US-374 passes: true
- **Learnings for future iterations:**
  - Anthropic `ImageBlockParam` source `media_type` must be `Literal["image/jpeg", "image/png", "image/gif", "image/webp"]` — assigning a plain `str` from ternary expression fails mypy --strict
  - `Path` used only in type annotations should go in `TYPE_CHECKING` block (ruff TC003) — with `from __future__ import annotations`, string annotations work at runtime
  - Service follows VlmAnalyzer pattern: constructor takes api_key + model + timeout, creates `anthropic.Anthropic` client
  - `_extract_json()` reused from VlmAnalyzer pattern — extracts JSON from ``` fences
  - Mocking pattern: `patch.object(interpreter._client.messages, "create", ...)` — same as VlmAnalyzer tests
  - For error fallback tests, use `anthropic.APITimeoutError(request=MagicMock())`, `anthropic.APIConnectionError(request=MagicMock())`, and `anthropic.RateLimitError(message=..., response=MagicMock(status_code=429, headers={}), body=None)`
---

## 2026-02-08 - US-378
- What was implemented: Scale verification safety rail via LLM in `cantena/geometry/scale_verify.py`. `ScaleVerifier` class with `verify_or_recover_scale(page, detected, text_blocks)` method that sends title-block text and candidate scale strings to Claude for verification/recovery. Uses narrow LLM inputs (title-block region text, candidate scale patterns). Decision logic: HIGH detected + LLM agrees ±5% → LLM_CONFIRMED; detected None + LLM HIGH/MEDIUM → LLM_RECOVERED; LLM disagrees >10% → keep DETERMINISTIC with warning; API failure/timeout/429 → UNVERIFIED with best deterministic scale.
- Files changed:
  - `backend/cantena/geometry/scale_verify.py` — new module: `ScaleVerifier`, `ScaleVerificationResult` (frozen dataclass), `VerificationSource` Literal type, `_build_user_text()`, `_find_scale_candidates()`, `_extract_json()`, `_parse_llm_json()` helpers
  - `backend/tests/test_scale_verify.py` — 18 tests across 7 test classes: TestDeterministicHighLlmAgrees (3), TestDeterministicNoneLlmRecovers (2), TestDisagreement (2), TestTimeoutAndErrors (4), TestLlmLowConfidence (2), TestMalformedResponse (2), TestScaleVerificationResultModel (3)
  - `backend/tests/integration/test_first_floor_scale_llm.py` — opt-in integration test: skips if ANTHROPIC_API_KEY missing; asserts LLM-verifier returns ~48.0 (±2) for first-floor.pdf
  - `prd.json` — US-378 passes: true
- **Learnings for future iterations:**
  - `VerificationSource` as `Literal["DETERMINISTIC", "LLM_CONFIRMED", "LLM_RECOVERED", "UNVERIFIED"]` is simpler than a StrEnum for a type alias used in one dataclass
  - Title-block region text extraction: filter text blocks by y >= 80% of page height
  - Scale candidate detection regex: `(?:scale|1/\d+|1:\d+|\d+/\d+\s*[\"'=])` catches most scale-like text
  - `anthropic.APIStatusError` is the base class for 401/403/500 errors — catching it alongside the specific errors (Timeout, Connection, RateLimit) provides complete coverage
  - `_extract_json()` pattern duplicated from llm_geometry_interpreter.py — could be refactored to shared utility later
  - Comparison thresholds: ≤5% exact match, ≤10% confirmed with note, >10% disagreement — mirrors typical construction tolerance levels
---

## 2026-02-08 - US-375
- What was implemented: Updated MeasurementService to use room-based area computation via RoomDetector, with optional LLM enrichment and scale verification. `PageMeasurements` extended with `rooms`, `room_count`, `polygonize_success`, `llm_interpretation`, and `scale_verification` fields. `MeasurementService` constructor now takes optional `llm_interpreter: LlmGeometryInterpreter | None` and `scale_verifier: ScaleVerifier | None`. Area computation priority: (1) sum of polygonized room areas (HIGH), (2) convex hull (MEDIUM), (3) page-size estimate (LOW). Confidence reflects which area method was used and whether scale was verified/confirmed.
- Files changed:
  - `backend/cantena/geometry/measurement.py` — extended `PageMeasurements` with room/LLM/scale-verification fields; updated `MeasurementService.__init__()` with optional `llm_interpreter` and `scale_verifier`; updated `measure()` to run RoomDetector.detect_rooms() + label_rooms(), scale verification, LLM enrichment, and area priority logic; added `_run_llm_enrichment()` helper
  - `backend/tests/test_measurement_rooms.py` — new file: 15 tests across 7 test classes (TestRoomsIncludedWhenPolygonizeWorks, TestPolygonizedTotalCloserThanConvexHull, TestFallbackToConvexHull, TestRoomCountAndPolygonizeSuccess, TestWithoutLlmInterpreter, TestWithScaleVerifier, TestBackwardCompatibility)
  - `prd.json` — US-375 passes: true
- **Learnings for future iterations:**
  - `from __future__ import annotations` makes all type annotations strings at runtime — so `TYPE_CHECKING`-only imports work for constructor parameters (`ScaleVerifier`, `LlmGeometryInterpreter`)
  - Deferred import of `RoomDetector` inside `measure()` avoids circular imports (rooms.py imports from extractor.py which measurement.py also imports)
  - Ruff SIM102 catches nested `if` statements — combine with `and` instead of nesting
  - `MeasurementService` backward compatibility: new optional constructor params default to `None`; new `PageMeasurements` fields have default values; all 8 existing tests pass unchanged
  - Room-based area uses `room_analysis.total_area_sf` directly when `polygonize_success` is True, avoiding redundant pts-to-sf conversion
---

## 2026-02-08 - US-376
- What was implemented: Real API integration tests in `tests/integration/test_first_floor_llm.py` that run the full enhanced pipeline (geometry + room detection + LLM interpretation + scale verification) on first-floor.pdf using real Anthropic API calls. Five test classes covering: LLM room interpretation (building type, structural system, room labels, special conditions), LLM with vision input (rendered page image), full pipeline accuracy (area/scale/room count), room area improvement over convex hull, and enhanced measurement report generation. Also registered the `llm` pytest mark in `pyproject.toml` to satisfy `--strict-markers`.
- Files changed:
  - `backend/tests/integration/test_first_floor_llm.py` — new file: 5 tests across 5 test classes (TestLlmRoomInterpretation, TestLlmWithImage, TestFullPipelineAccuracy, TestRoomAreaImprovementOverConvexHull, TestMeasurementReportWithRooms)
  - `backend/pyproject.toml` — added `markers = ["llm: ..."]` to `[tool.pytest.ini_options]`
  - `prd.json` — US-376 passes: true
- **Learnings for future iterations:**
  - `--strict-markers` in pytest requires all custom marks to be registered in `pyproject.toml` under `markers`; unregistered marks cause `PytestUnknownMarkWarning` (warning, not error, but should be fixed)
  - Rate limit handling pattern: wrap `service.measure(page)` in a helper that catches `Exception` and checks `"429" in str(exc)` → `pytest.skip("Rate limited")`
  - Page rendering for vision input: `page.get_pixmap(matrix=fitz.Matrix(2.0, 2.0))` gives 144 DPI; save to temp PNG with `.save(tmp.name)`
  - `fitz` module import for runtime use (Matrix, get_pixmap) must be inside the test function body to avoid import errors in TYPE_CHECKING-only environments
  - The `_build_service()` helper pattern keeps test methods clean while allowing all tests to create fresh service instances with LLM+verifier enabled
---

