## Codebase Patterns
- All source files use `from __future__ import annotations`
- Frozen dataclasses for immutable models (`@dataclass(frozen=True)`)
- `StrEnum` for string-based enumerations (not `(str, Enum)`)
- `TYPE_CHECKING` block for expensive imports (fitz, etc.)
- `Point2D` and `BoundingRect` from `cantena.geometry.extractor`
- `WallSegment` and `WallAnalysis` from `cantena.geometry.walls`
- `TextBlock` and `ScaleResult` from `cantena.geometry.scale`
- Union-find clustering for endpoint snapping (O(n²) pairwise, KDTree upgrade path documented)
- mypy runs slow on first invocation — use `--no-incremental` if it hangs
- Use `.venv/bin/ruff` and `.venv/bin/mypy` directly (not `python3 -m`)
- `dataclasses.replace()` for updating frozen dataclass instances (not `dataclasses.asdict()` + constructor)
- Room label matching uses `_ROOM_NAMES` frozenset with longest-first substring matching
- Anthropic `ImageBlockParam` `media_type` requires `Literal["image/jpeg", "image/png", "image/gif", "image/webp"]` — plain `str` fails mypy
- `Path` import goes in `TYPE_CHECKING` block when only used in annotations (ruff TC003)
- `ScaleVerifier` and `ScaleVerificationResult` from `cantena.geometry.scale_verify`
- LLM verification decision logic: ±5% confirmed, ±10% confirmed+warning, >10% keep deterministic+warning
- `VerificationSource` is a `Literal` type alias, not an enum (keeps it simple for dataclass field)
- Register custom pytest marks (e.g., `llm`) in `pyproject.toml` under `[tool.pytest.ini_options]` markers — `--strict-markers` enforces this
- LLM integration tests: `_get_api_key()` helper + `pytest.skip()` for missing API key; catch 429 with `pytest.skip("Rate limited")`
- PIL semi-transparent overlays: convert to RGBA, draw on separate `Image.new("RGBA")` overlay, `Image.alpha_composite()`, then convert back to RGB for PNG
- `RoomType` StrEnum in `cantena.models.enums` — 35 room types covering residential, commercial, education, healthcare, industrial
- `RoomTypeCost` Pydantic model in `cantena.data.room_costs` — room-level cost data with cost_drivers and typical_percent_of_building
- Building type → room cost category mapping: `_RESIDENTIAL_TYPES`, `_OFFICE_TYPES`, `_SCHOOL_TYPES` frozensets in `room_costs.py`
- `SpaceProgram` Pydantic model in `cantena.models.space_program` — bridges DetectedRoom/LLM/assumed to cost engine
- `LABEL_TO_ROOM_TYPE` dict in `space_program.py` maps drawing labels (e.g., "COATS") to RoomType enum
- `SpaceSource` StrEnum: GEOMETRY, LLM, ASSUMED, USER_OVERRIDE — tracks provenance of each Space
- Pydantic mutable models allow direct field assignment (`space.source = SpaceSource.USER_OVERRIDE`) unlike frozen dataclasses
- `SpaceAssembler` in `cantena.services.space_assembler` — priority: geometry → LLM → assumed; enriches geometry with LLM; reconciles area gaps explicitly
- `PipelineResult` extended with `space_program`, `space_breakdown`, `room_detection_method` for enhanced pipeline
- `AnalysisPipeline` accepts optional `space_assembler: SpaceAssembler` — when provided + geometry available, assembles SpaceProgram and passes to CostEngine
- `create_pipeline()` in `deps.py` wires up HybridAnalyzer + SpaceAssembler for full enhanced flow
- `room_detection_method` values: `"polygonize"` (geometry), `"llm_only"` (LLM), `"assumed"` (no rooms detected)
- `POST /api/estimate` uses `EstimateRequest` wrapper model: `{"building": BuildingModel, "space_program": SpaceProgram | None}` — NOT flat BuildingModel body
- Imports after `load_dotenv()` in `app.py` need `# noqa: E402` — pre-existing pattern for FastAPI runtime-resolved models

---

## 2026-02-08 - US-371
- What was implemented: Endpoint snapping module `cantena/geometry/snap.py` with `snap_endpoints()` and `snap_to_grid()` functions. Uses union-find clustering to snap wall segment endpoints within a configurable tolerance (default 3.0 pts), replacing each cluster with its centroid. Removes duplicate segments after snapping. Includes `snap_to_grid()` helper for rounding to grid points.
- Files changed:
  - `backend/cantena/geometry/snap.py` — new module: `snap_endpoints(segments, tolerance_pts)`, `snap_to_grid(point, grid_size_pts)`, `_cluster_endpoints()` with union-find, `_reclassify_orientation()`, `_distance()` helper
  - `backend/tests/test_snap.py` — 13 tests: 8 in TestSnapEndpoints (within/outside tolerance, duplicate removal, empty input, exact match, thickness preservation, length recompute, three-way cluster) + 5 in TestSnapToGrid (nearest grid, unchanged, half-round, custom/large grid sizes)
  - `prd.json` — US-371 passes: true
- **Learnings for future iterations:**
  - Unused imports (e.g., `dataclass` if not used in file) trigger ruff F401 — check before committing
  - mypy `--no-incremental` flag needed when mypy hangs on first run
  - Union-find with path compression is simple and effective for endpoint clustering
  - Orientation is reclassified after snapping since endpoint movement can change angle
  - Duplicate detection uses canonical (min, max) pair keys for order-independence
---

## 2026-02-08 - US-351
- What was implemented: Integration test fixtures and smoke tests for first-floor.pdf — conftest.py with `first_floor_pdf` and `first_floor_page` fixtures, ground truth constants, and smoke test file verifying PDF loads, page count, dimensions, and text content.
- Files changed:
  - `backend/tests/integration/__init__.py` — new integration test package
  - `backend/tests/integration/conftest.py` — `first_floor_pdf` fixture (yields fitz.Document, closes on teardown), `first_floor_page` fixture (yields first page), ground truth constants (EXPECTED_SCALE_FACTOR=48.0, EXPECTED_OVERALL_WIDTH_FT=32.0, EXPECTED_OVERALL_DEPTH_FT=16.0, EXPECTED_GROSS_AREA_SF=512.0, EXPECTED_TOTAL_WITH_PORCHES_SF=700.0, EXPECTED_ROOM_COUNT=7)
  - `backend/tests/integration/test_first_floor_smoke.py` — 4 smoke tests: PDF loads, has exactly 1 page, page has non-zero dimensions, page contains text
  - `prd.json` — US-351 passes: true
- **Learnings for future iterations:**
  - `test_pdfs/` is at repo root, not in `backend/` — `Path(__file__).resolve().parents[3]` from `tests/integration/conftest.py` reaches the repo root
  - `Generator` import from `collections.abc` needs to go in `TYPE_CHECKING` block per ruff TC003
  - Empty `if TYPE_CHECKING: pass` blocks trigger ruff TC005 — just remove them if unused
  - Integration test fixtures use `Generator` return type for yield fixtures that need cleanup
---

## 2026-02-08 - US-352
- What was implemented: Integration tests validating VectorExtractor against the real first-floor.pdf — verifies path count (>=50), line/rect stats, bounding box coverage (>=50% width, >=40% height), line width distribution (>=2 distinct widths), stroke color majority, filter_by_region reduction, and rasterized PDF skip fallback.
- Files changed:
  - `backend/tests/integration/test_first_floor_vectors.py` — 8 tests across TestVectorExtraction (7 tests) and TestRasterizedFallback (1 test)
  - `prd.json` — US-352 passes: true
- **Learnings for future iterations:**
  - VectorExtractor on first-floor.pdf extracts hundreds of paths — PDF has rich vector data, not rasterized
  - Line width distribution is logged for debugging wall detection thresholds — useful for US-354 tuning
  - `Counter[float]` typing works cleanly for counting line width occurrences
  - f-strings without placeholders trigger ruff F541 — use plain strings for static text
  - Integration tests with `print()` output need `-s` flag to see during development, but pass without it
---

## 2026-02-08 - US-353
- What was implemented: Integration tests validating ScaleDetector on the real first-floor.pdf, plus a two-step text normalization approach in `detect_from_text` (Unicode canonicalization + tolerant regex parsing). Tests cover text block extraction (>=20 blocks), scale detection from page text (scale_factor ~48.0), all 11 dimension string parses, dimension-based inference attempt, messy format resilience (Unicode quotes, extra whitespace, prime symbols), and correct behavior without API text interpreter.
- Files changed:
  - `backend/cantena/geometry/scale.py` — added `_normalize_scale_text()` function for two-step approach: normalizes Unicode quotes (\u201c/\u201d/\u2033/\u2018/\u2019/\u2032) to ASCII and collapses whitespace before regex matching
  - `backend/tests/integration/test_first_floor_scale.py` — new file: 23 tests across 6 test classes (TestTextBlockExtraction, TestDetectFromText, TestParseDimensionStrings, TestDetectFromDimensions, TestMessyFormatResilience, TestNoApiTextInterpreter)
  - `prd.json` — US-353 passes: true
- **Learnings for future iterations:**
  - Real PDF scale text is `SCALE: 1/4" =1'-0"` (note space before `=`) — existing regex already handles this but normalization makes it more robust
  - `detect_from_dimensions` on this drawing returns scale_factor ~144 (not ~48) because the closest dimension/line pairing is a short annotation line with a dimension value — dimension calibration is a fallback, not primary
  - The PDF has 118 text blocks total — plenty for analysis
  - `_normalize_scale_text` replaces all common Unicode quote variants (\u201c, \u201d, \u2033, \u2018, \u2019, \u2032, \u201e, \u00ab, \u00bb) to ASCII equivalents
  - Two-step approach (normalize → parse) is more resilient than adding more Unicode alternatives to regex character classes
---

## 2026-02-08 - US-354
- What was implemented: Integration tests validating WallDetector on the real first-floor.pdf, plus tuning of WallDetector heuristics to produce accurate results. Tests cover: ≥8 wall segments (got 42), ≥3 H/V each (23 H, 19 V), total wall length 80-250 LF (got 227.5), enclosed area 380-700 SF (got 548.0, +7% error vs 512 SF), wall thickness 3-12" (got 6.2"), and a diagnostic summary.
- Files changed:
  - `backend/tests/integration/test_first_floor_walls.py` — new file: 7 tests across TestWallDetection class (segment count, H/V counts, wall length range, area range, thickness range, diagnostic summary)
  - `backend/cantena/geometry/walls.py` — added `_MIN_WALL_LENGTH_PTS = 36` minimum segment length filter (excludes annotation ticks, dimension leader lines) and `_remove_length_outliers()` IQR-based outlier removal (excludes title block borders)
  - `prd.json` — US-354 passes: true
- **Learnings for future iterations:**
  - Unfiltered WallDetector picked up 238 segments (385 LF, 1771 SF area) — mostly annotation ticks and short marks under 1 ft
  - Two line widths on this drawing: 1.134 pts (dimension/annotation lines) and 1.417 pts (structural walls)
  - Minimum length filter of 36 pts (~2 ft at 1/4" scale) removed 181 out of 238 annotation/tick segments
  - Title block border was a 53.4 ft line at Y=751 spanning full page — IQR method (Q3 + 3*IQR upper bound) correctly identified and removed it
  - Dimension annotation leader lines at Y=86 and Y=684 (1.2 ft each) were also removed by the 36pt minimum length filter
  - Convex hull of wall endpoints gives ~548 SF (7% over expected 512 SF) — includes some porch area but well within ±25% tolerance
  - Wall thickness detection via parallel pair analysis: median 6.2 inches (~10.5 pts gap between parallel wall lines)
  - `pts_to_real_lf(pts, scale)` and `pts_to_real_sf(pts, scale)` from measurement.py are the correct conversion functions for integration tests
---

## 2026-02-08 - US-355
- What was implemented: Integration tests validating full MeasurementService.measure() pipeline on first-floor.pdf — verifies end-to-end measurement (scale detection → wall detection → area/perimeter/wall length computation), plus resilience tests with mocked mangled scale text ensuring graceful degradation.
- Files changed:
  - `backend/tests/integration/test_first_floor_measurement.py` — new file: 9 tests across TestMeasurementPipeline (7 tests) and TestMangledScaleResilience (2 tests)
  - `prd.json` — US-355 passes: true
- **Learnings for future iterations:**
  - MeasurementService.measure() on first-floor.pdf achieves HIGH confidence: scale_factor=48.0, gross_area=548.0 SF (+7% vs 512), perimeter=97.9 LF, wall_length=227.5 LF, 42 walls
  - When text extraction returns empty blocks (mangled text), detect_from_text and detect_from_dimensions both return None → pipeline falls back to estimated scale (factor=96) with LOW confidence, area balloons to ~2192 SF (because scale_factor doubles)
  - `patch.object(ScaleDetector, "extract_text_blocks", return_value=[])` is the cleanest way to simulate text extraction failure without needing a real mangled PDF
  - The pipeline never crashes on missing text — graceful degradation works: result is always returned, confidence degrades to LOW
---

## 2026-02-08 - US-356
- What was implemented: Integration tests validating text and room label extraction from first-floor.pdf — verifies all 9 expected room labels found (case-insensitive with newline normalization), label positions within drawing content area, spatial separation of distinct label blocks, coarse left/right zone mapping, at least 10 dimension text blocks, and title block fields (SCALE, 1/4, A1.2, 1ST FLOOR, AMERICAN FARMHOUSE) in border areas.
- Files changed:
  - `backend/tests/integration/test_first_floor_rooms.py` — new file: 6 tests across 6 test classes (TestRoomLabelExtraction, TestRoomLabelPositions, TestRoomLabelSpatialSeparation, TestCoarseZoneMapping, TestDimensionBlocks, TestTitleBlockFields)
  - `prd.json` — US-356 passes: true
- **Learnings for future iterations:**
  - PyMuPDF text blocks may contain multiple room labels in one block (e.g. "LIVING ROOM\nKITCHEN") — normalize newlines to spaces before label matching
  - "BACK PORCH" appears as "BACK \nPORCH" (split across lines within one text block) — `re.sub(r"\s+", " ", text)` normalization is essential
  - Title block text uses spaced-out characters: "A M E R I C A N  F A R M H O U S E" — collapse with `re.sub(r"\b(\w) (?=\w\b)", r"\1", text)` then normalize remaining whitespace
  - Title block elements spread across page edges: SCALE at lower-left (148, 760), AMERICAN FARMHOUSE at right-center (1161, 363), sheet number at lower-right (1152, 766) — search border areas (right 15% OR bottom 15%) not just lower-right quadrant
  - Spatial separation test must de-duplicate by text block position — labels sharing the same PDF text block (e.g. LIVING ROOM + KITCHEN at distance 0) are acceptable for open-plan rooms
  - 21 dimension text blocks found, well above the 10 minimum threshold
  - All 9 room labels found, distributed: left half (4): LIVING ROOM, KITCHEN, FRONT PORCH, LAUNDRY; right half (5): DINING, BACK PORCH, UTILITY, WC, COATS
---

## 2026-02-08 - US-357
- What was implemented: Geometry accuracy report generation and minimum threshold assertion tests — capstone integration test that runs the full pipeline on first-floor.pdf, writes a comprehensive markdown report to test_results/first-floor-geometry-report.md, and verifies minimum accuracy thresholds (scale ±10%, area ±30%, ≥6 room labels).
- Files changed:
  - `backend/tests/integration/test_first_floor_report.py` — new file: TestReportGeneration (1 test: generates full report with Drawing Info, Measurement Results, Text Extraction, Confidence Assessment, Scale Detection Path, Known Limitations, and Recommendations sections), TestMinimumThresholds (3 tests: scale factor ±10%, gross area ±30%, ≥6 room labels)
  - `test_results/first-floor-geometry-report.md` — generated report file (created by test)
  - `prd.json` — US-357 passes: true
- **Learnings for future iterations:**
  - Report results: Scale factor 48.0 (exact match), gross area 548.0 SF (+7.0% vs 512 SF expected), perimeter 97.9 LF (+2.0% vs 96 LF expected), 42 walls (23H, 19V), wall thickness ~6.2"
  - All confidence components rated HIGH: scale detection (deterministic text normalization/parsing), wall detection (≥8 segments + outer boundary), text extraction (9/9 room labels)
  - `datetime.UTC` alias required (not `timezone.utc`) per ruff UP017
  - Report-generation test always passes (diagnostic tool) but must assert file creation
  - Threshold tests are separate from the report test to clearly distinguish pass/fail assertions from diagnostic output
---

## 2026-02-08 - US-372
- What was implemented: Room polygon reconstruction via Shapely polygonize in `cantena/geometry/rooms.py`. `RoomDetector` class with `detect_rooms()` method that snaps endpoints (US-371), extends segments by 1pt, converts to Shapely LineStrings, unions linework, calls `polygonize()`, filters tiny artifacts (<100 sq pts) and page boundary polygons (>80% page area), and falls back to convex hull if polygonize produces 0 rooms. Includes `DetectedRoom` and `RoomAnalysis` frozen dataclasses with area/perimeter conversion to SF/LF when scale provided.
- Files changed:
  - `backend/cantena/geometry/rooms.py` — new module: `RoomDetector.detect_rooms()`, `DetectedRoom` (frozen dataclass), `RoomAnalysis` (frozen dataclass), `_extend_segment()`, `_polygon_to_detected_room()`, `_convex_hull_fallback()`
  - `backend/tests/test_rooms.py` — 18 tests across 8 test classes: TestDetectRoomsSingleRectangle (4), TestDetectRoomsTwoAdjacent (2), TestSmallGapsSnapped (1), TestNonClosingFallback (1), TestTinyArtifactsFiltered (1), TestEmptyInput (2), TestPageBoundaryFilter (1), TestRoomAnalysisModel (6)
  - `prd.json` — US-372 passes: true
- **Learnings for future iterations:**
  - Shapely's `polygonize()` requires exact endpoint equality — snapping (US-371) + segment extension (1pt) ensures overlapping linework for polygon formation
  - Deferred Shapely imports inside methods (`from shapely.geometry import ...`) to avoid circular imports and keep TYPE_CHECKING clean
  - Area conversion: `area_sf = area_pts / (72^2) * scale_factor^2 / 144`; Perimeter: `perimeter_lf = perimeter_pts / 72 * scale_factor / 12`
  - `_convex_hull_fallback()` returns `polygonize_success=False` so downstream code can distinguish accurate room-based area from approximate hull area
  - `unary_union(lines)` before `polygonize()` is essential — it nodes intersections so polygonize can find closed loops
---

## 2026-02-08 - US-373
- What was implemented: Room label matching in `cantena/geometry/rooms.py` — `RoomDetector.label_rooms()` method that associates text labels with detected room polygons. Uses a curated `_ROOM_NAMES` frozenset (37 common room names), case-insensitive matching with whitespace normalization, Shapely polygon containment checks, nearest-centroid fallback within 50pts, and duplicate label indexing (e.g. BEDROOM 1, BEDROOM 2). Uses `dataclasses.replace()` to create new frozen DetectedRoom instances with labels.
- Files changed:
  - `backend/cantena/geometry/rooms.py` — added `_ROOM_NAMES` frozenset, `_MAX_LABEL_DISTANCE_PTS` constant, `_normalize_label_text()`, `_match_room_name()` helpers, `RoomDetector.label_rooms()` method; added `re` and `replace` imports; added `TextBlock` to TYPE_CHECKING block
  - `backend/tests/test_room_labels.py` — new file: 9 tests across 8 test classes (TestLabelInsidePolygon, TestLabelOutsideAssignsNearest, TestNonRoomTextIgnored, TestUnlabeledRoomsRemainNone, TestDuplicateNamesGetIndexed, TestCaseInsensitiveMatching, TestEmptyInputs, TestSubstringMatch)
  - `prd.json` — US-373 passes: true
- **Learnings for future iterations:**
  - Shapely `poly.contains(pt)` returns False for points exactly on boundary — use `poly.boundary.distance(pt) < 1.0` as fallback
  - Ruff SIM102 requires combining nested `if` statements with `and` instead of nesting
  - For "outside label assigns to nearest" tests, room centroid must be within 50pts of the outside label position — large rooms have centroids far from edges
  - Shapely coordinate sequences yield `tuple[float, ...]` not `tuple[float, float]` — must cast explicitly for mypy --strict
  - `dataclasses.replace()` is the clean way to update frozen dataclass fields
---

## 2026-02-08 - US-374
- What was implemented: LLM-assisted geometry interpretation service in `cantena/services/llm_geometry_interpreter.py`. `LlmGeometryInterpreter` class that sends extracted geometry data (rooms, measurements, text blocks) and optionally a PDF page image to Claude for semantic analysis. Returns `LlmInterpretation` with building_type, structural_system, per-room confirmed labels/types, special conditions, measurement flags, and confidence notes. Gracefully falls back to default UNKNOWN interpretation on any API error (timeout, 429, malformed response).
- Files changed:
  - `backend/cantena/services/llm_geometry_interpreter.py` — new module: `LlmGeometryInterpreter.interpret()`, `GeometrySummary`, `RoomSummary`, `LlmInterpretation`, `LlmRoomInterpretation` (all frozen dataclasses), `_serialize_geometry_summary()`, `_extract_json()`, `_build_interpretation()` helpers
  - `backend/tests/test_llm_geometry_interpreter.py` — 17 tests across 7 test classes: TestWellFormedResponse (4), TestMalformedResponse (3), TestTimeoutFallback (3), TestGeometrySummarySerialization (3), TestVisionInput (3), TestDefaultInterpretation (1)
  - `prd.json` — US-374 passes: true
- **Learnings for future iterations:**
  - Anthropic `ImageBlockParam` source `media_type` must be `Literal["image/jpeg", "image/png", "image/gif", "image/webp"]` — assigning a plain `str` from ternary expression fails mypy --strict
  - `Path` used only in type annotations should go in `TYPE_CHECKING` block (ruff TC003) — with `from __future__ import annotations`, string annotations work at runtime
  - Service follows VlmAnalyzer pattern: constructor takes api_key + model + timeout, creates `anthropic.Anthropic` client
  - `_extract_json()` reused from VlmAnalyzer pattern — extracts JSON from ``` fences
  - Mocking pattern: `patch.object(interpreter._client.messages, "create", ...)` — same as VlmAnalyzer tests
  - For error fallback tests, use `anthropic.APITimeoutError(request=MagicMock())`, `anthropic.APIConnectionError(request=MagicMock())`, and `anthropic.RateLimitError(message=..., response=MagicMock(status_code=429, headers={}), body=None)`
---

## 2026-02-08 - US-378
- What was implemented: Scale verification safety rail via LLM in `cantena/geometry/scale_verify.py`. `ScaleVerifier` class with `verify_or_recover_scale(page, detected, text_blocks)` method that sends title-block text and candidate scale strings to Claude for verification/recovery. Uses narrow LLM inputs (title-block region text, candidate scale patterns). Decision logic: HIGH detected + LLM agrees ±5% → LLM_CONFIRMED; detected None + LLM HIGH/MEDIUM → LLM_RECOVERED; LLM disagrees >10% → keep DETERMINISTIC with warning; API failure/timeout/429 → UNVERIFIED with best deterministic scale.
- Files changed:
  - `backend/cantena/geometry/scale_verify.py` — new module: `ScaleVerifier`, `ScaleVerificationResult` (frozen dataclass), `VerificationSource` Literal type, `_build_user_text()`, `_find_scale_candidates()`, `_extract_json()`, `_parse_llm_json()` helpers
  - `backend/tests/test_scale_verify.py` — 18 tests across 7 test classes: TestDeterministicHighLlmAgrees (3), TestDeterministicNoneLlmRecovers (2), TestDisagreement (2), TestTimeoutAndErrors (4), TestLlmLowConfidence (2), TestMalformedResponse (2), TestScaleVerificationResultModel (3)
  - `backend/tests/integration/test_first_floor_scale_llm.py` — opt-in integration test: skips if ANTHROPIC_API_KEY missing; asserts LLM-verifier returns ~48.0 (±2) for first-floor.pdf
  - `prd.json` — US-378 passes: true
- **Learnings for future iterations:**
  - `VerificationSource` as `Literal["DETERMINISTIC", "LLM_CONFIRMED", "LLM_RECOVERED", "UNVERIFIED"]` is simpler than a StrEnum for a type alias used in one dataclass
  - Title-block region text extraction: filter text blocks by y >= 80% of page height
  - Scale candidate detection regex: `(?:scale|1/\d+|1:\d+|\d+/\d+\s*[\"'=])` catches most scale-like text
  - `anthropic.APIStatusError` is the base class for 401/403/500 errors — catching it alongside the specific errors (Timeout, Connection, RateLimit) provides complete coverage
  - `_extract_json()` pattern duplicated from llm_geometry_interpreter.py — could be refactored to shared utility later
  - Comparison thresholds: ≤5% exact match, ≤10% confirmed with note, >10% disagreement — mirrors typical construction tolerance levels
---

## 2026-02-08 - US-375
- What was implemented: Updated MeasurementService to use room-based area computation via RoomDetector, with optional LLM enrichment and scale verification. `PageMeasurements` extended with `rooms`, `room_count`, `polygonize_success`, `llm_interpretation`, and `scale_verification` fields. `MeasurementService` constructor now takes optional `llm_interpreter: LlmGeometryInterpreter | None` and `scale_verifier: ScaleVerifier | None`. Area computation priority: (1) sum of polygonized room areas (HIGH), (2) convex hull (MEDIUM), (3) page-size estimate (LOW). Confidence reflects which area method was used and whether scale was verified/confirmed.
- Files changed:
  - `backend/cantena/geometry/measurement.py` — extended `PageMeasurements` with room/LLM/scale-verification fields; updated `MeasurementService.__init__()` with optional `llm_interpreter` and `scale_verifier`; updated `measure()` to run RoomDetector.detect_rooms() + label_rooms(), scale verification, LLM enrichment, and area priority logic; added `_run_llm_enrichment()` helper
  - `backend/tests/test_measurement_rooms.py` — new file: 15 tests across 7 test classes (TestRoomsIncludedWhenPolygonizeWorks, TestPolygonizedTotalCloserThanConvexHull, TestFallbackToConvexHull, TestRoomCountAndPolygonizeSuccess, TestWithoutLlmInterpreter, TestWithScaleVerifier, TestBackwardCompatibility)
  - `prd.json` — US-375 passes: true
- **Learnings for future iterations:**
  - `from __future__ import annotations` makes all type annotations strings at runtime — so `TYPE_CHECKING`-only imports work for constructor parameters (`ScaleVerifier`, `LlmGeometryInterpreter`)
  - Deferred import of `RoomDetector` inside `measure()` avoids circular imports (rooms.py imports from extractor.py which measurement.py also imports)
  - Ruff SIM102 catches nested `if` statements — combine with `and` instead of nesting
  - `MeasurementService` backward compatibility: new optional constructor params default to `None`; new `PageMeasurements` fields have default values; all 8 existing tests pass unchanged
  - Room-based area uses `room_analysis.total_area_sf` directly when `polygonize_success` is True, avoiding redundant pts-to-sf conversion
---

## 2026-02-08 - US-376
- What was implemented: Real API integration tests in `tests/integration/test_first_floor_llm.py` that run the full enhanced pipeline (geometry + room detection + LLM interpretation + scale verification) on first-floor.pdf using real Anthropic API calls. Five test classes covering: LLM room interpretation (building type, structural system, room labels, special conditions), LLM with vision input (rendered page image), full pipeline accuracy (area/scale/room count), room area improvement over convex hull, and enhanced measurement report generation. Also registered the `llm` pytest mark in `pyproject.toml` to satisfy `--strict-markers`.
- Files changed:
  - `backend/tests/integration/test_first_floor_llm.py` — new file: 5 tests across 5 test classes (TestLlmRoomInterpretation, TestLlmWithImage, TestFullPipelineAccuracy, TestRoomAreaImprovementOverConvexHull, TestMeasurementReportWithRooms)
  - `backend/pyproject.toml` — added `markers = ["llm: ..."]` to `[tool.pytest.ini_options]`
  - `prd.json` — US-376 passes: true
- **Learnings for future iterations:**
  - `--strict-markers` in pytest requires all custom marks to be registered in `pyproject.toml` under `markers`; unregistered marks cause `PytestUnknownMarkWarning` (warning, not error, but should be fixed)
  - Rate limit handling pattern: wrap `service.measure(page)` in a helper that catches `Exception` and checks `"429" in str(exc)` → `pytest.skip("Rate limited")`
  - Page rendering for vision input: `page.get_pixmap(matrix=fitz.Matrix(2.0, 2.0))` gives 144 DPI; save to temp PNG with `.save(tmp.name)`
  - `fitz` module import for runtime use (Matrix, get_pixmap) must be inside the test function body to avoid import errors in TYPE_CHECKING-only environments
  - The `_build_service()` helper pattern keeps test methods clean while allowing all tests to create fresh service instances with LLM+verifier enabled
---

## 2026-02-08 - US-377
- What was implemented: Enhanced debug visualization endpoint (`POST /api/debug/geometry`) to overlay detected room polygons with semi-transparent color fills, room labels at centroids, and area annotations. Extended JSON response with `rooms[]` array (room_index, label, area_sf, perimeter_lf, polygon_vertices, centroid) and optional `llm_interpretation` object. Uses RGBA alpha compositing for semi-transparent room fills — 8 distinct colors for labeled rooms, gray for unlabeled rooms (shown as "?" + area). Backward compatible: if no rooms detected, falls back to existing wall/boundary overlay.
- Files changed:
  - `backend/cantena/api/debug.py` — added `_draw_room_overlays()` function with semi-transparent polygon fills (RGBA alpha composite), room label text at centroids, area SF below labels; added `_ROOM_COLORS` and `_GRAY_FILL` constants; updated `_measurements_to_dict()` to include `rooms[]` with polygon_vertices/centroid and optional `llm_interpretation`; refactored overlay rendering to use RGBA overlay + alpha_composite + final RGB conversion
  - `backend/tests/test_debug_rooms.py` — new file: 5 tests across 2 test classes (TestDebugRoomsPngOverlay: room pixels tinted, no-rooms fallback; TestDebugRoomsJson: rooms array structure, empty rooms, backward-compatible fields)
  - `prd.json` — US-377 passes: true
- **Learnings for future iterations:**
  - PIL `ImageDraw.Draw(img).polygon(fill=rgba)` requires RGBA image mode — convert base from RGB to RGBA, draw on separate overlay, then `Image.alpha_composite()` to merge
  - Convert back to RGB before saving PNG to avoid inflated file sizes from unnecessary alpha channel
  - `draw.text(anchor="mm")` centers text at the given point (middle-middle) — useful for room labels at centroids
  - Synthetic test PDFs with two adjacent rooms (rectangle split by dividing wall) reliably produce polygonize rooms for testing
  - Pixel sampling in tests: multiply room centroid coords by zoom factor to find the pixel position in the output PNG
---

## 2026-02-08 - US-401
- What was implemented: Room-type cost differentiation data — `RoomType` StrEnum (35 values) in `cantena/models/enums.py`, `RoomTypeCost` Pydantic model and seed data in `cantena/data/room_costs.py` covering residential (13 room types), office (9 room types), school (3 room types), and hospital (3 room types). `CostDataRepository` extended with `get_room_type_costs(building_type)` method. Building types mapped to cost categories: residential types → residential costs, office/retail/warehouse → office costs, schools → school costs, hospital → hospital costs.
- Files changed:
  - `backend/cantena/models/enums.py` — added `RoomType` StrEnum with 35 values (residential, commercial, education, healthcare, industrial, circulation, fallback)
  - `backend/cantena/data/room_costs.py` — new module: `RoomTypeCost` Pydantic model, seed cost data lists (`RESIDENTIAL_ROOM_COSTS`, `OFFICE_ROOM_COSTS`, `SCHOOL_ROOM_COSTS`, `HOSPITAL_ROOM_COSTS`), `get_room_costs_for_building_type()` lookup function with building type category mapping
  - `backend/cantena/data/repository.py` — added `get_room_type_costs()` method delegating to `room_costs` module
  - `backend/cantena/models/__init__.py` — exported `RoomType`
  - `backend/cantena/data/__init__.py` — exported `RoomTypeCost`
  - `backend/tests/test_room_costs.py` — 18 tests across 3 test classes (TestRoomCostData: 9, TestCostDataRepositoryRoomTypes: 4, TestBuildingTypeMapping: 5)
  - `prd.json` — US-401 passes: true
- **Learnings for future iterations:**
  - `ruff check --fix` auto-fixes I001 import sorting — always run after creating new files
  - Pydantic models for cost data use direct imports (not TYPE_CHECKING) since `runtime-evaluated-base-classes` in ruff config handles TCH001
  - Building type category mapping uses `frozenset` for efficient membership testing
  - Seed data typical_percent_of_building values must sum to 90-110% per category (AC requirement)
  - `get_room_costs_for_building_type()` is the free function; `CostDataRepository.get_room_type_costs()` is the repository method that delegates to it
---

## 2026-02-08 - US-402
- What was implemented: Space program model with DetectedRoom bridge — `SpaceProgram` Pydantic model in `cantena/models/space_program.py` with three factory classmethods (`from_detected_rooms`, `from_llm_interpretation`, `from_building_model`), `Space` model with room_type/name/area_sf/count/source/confidence fields, `SpaceSource` StrEnum, and `LABEL_TO_ROOM_TYPE` mapping dict. `update_space()` method for user overrides.
- Files changed:
  - `backend/cantena/models/space_program.py` — new module: `SpaceSource` StrEnum, `LABEL_TO_ROOM_TYPE` dict (37 label mappings), `Space` Pydantic model, `SpaceProgram` Pydantic model with `total_area_sf` computed property, `from_detected_rooms()`, `from_llm_interpretation()`, `from_building_model()`, `update_space()`
  - `backend/cantena/models/__init__.py` — exported `Space`, `SpaceProgram`, `SpaceSource`
  - `backend/tests/test_space_program.py` — 21 tests across 7 test classes (TestFromDetectedRoomsBasic, TestLabelMappings, TestUnlabeledRoom, TestFromBuildingModel, TestFromLlmInterpretation, TestTotalAreaSf, TestUpdateSpace)
  - `prd.json` — US-402 passes: true
- **Learnings for future iterations:**
  - `BuildingModel` imported in `TYPE_CHECKING` block (not at runtime) since `from __future__ import annotations` makes annotations strings — but must NOT use `# noqa: TCH001` or ruff F821 fires
  - Pydantic models are mutable by default — `update_space()` can directly assign fields unlike frozen dataclasses
  - `LlmRoomInterpretation.room_type_enum` is a string like "LIVING_ROOM" — convert with `RoomType(value.lower())` since RoomType uses lowercase values
  - Label-to-RoomType mapping strips numeric suffix (e.g., "BEDROOM 1" → look up "BEDROOM") via `rsplit(" ", 1)[0]`
  - `from_building_model` uses deferred import of `get_room_costs_for_building_type` to avoid circular imports between models and data layers
---

## 2026-02-08 - US-403
- What was implemented: Room-type-aware cost engine — `CostEngine.estimate()` extended with optional `space_program: SpaceProgram | None` parameter. When provided, each Space is priced using room-type-specific $/SF from RoomTypeCost data, with location factor and complexity multipliers applied per-room. `SpaceCost` Pydantic model added to `estimate.py` with fields: room_type, name, area_sf, cost_per_sf (CostRange), total_cost (CostRange), percent_of_total, source. `CostEstimate` extended with `space_breakdown: list[SpaceCost] | None`. Unmapped room types (e.g., LOADING_DOCK in residential context) fall back to whole-building $/SF rate. Space.count multiplier correctly scales area. Without SpaceProgram, existing behavior is completely preserved.
- Files changed:
  - `backend/cantena/models/estimate.py` — added `SpaceCost` model; added `space_breakdown` optional field to `CostEstimate`
  - `backend/cantena/engine.py` — extended `estimate()` signature with `space_program` param; added `_estimate_with_space_program()` private method; imported `SpaceCost` and `SpaceProgram` (TYPE_CHECKING)
  - `backend/cantena/models/__init__.py` — exported `SpaceCost`
  - `backend/tests/test_engine_rooms.py` — 15 tests across 7 test classes (TestResidentialRoomPricing, TestOfficeRoomPricing, TestTotalCostConsistency, TestBackwardCompatibility, TestOtherRoomTypeFallback, TestSourceTracking, TestSpaceCountMultiplier)
  - `prd.json` — US-403 passes: true
- **Learnings for future iterations:**
  - `_estimate_with_space_program()` uses deferred import of `get_room_costs_for_building_type` to avoid circular imports
  - Room cost lookup builds `cost_by_room_type` dict from `RoomTypeCost` list for O(1) per-space lookups
  - Fallback for unmapped room types uses the whole-building adjusted $/SF with standard 0.80/1.25 range factors
  - `SpaceCost.source` is a plain `str` (not SpaceSource enum) — maps from `Space.source.value` for JSON-friendly output
  - `percent_of_total` is computed in a second pass after all room costs are summed
  - `cost_per_sf` for the overall estimate uses weighted average (total_cost / total_area) when SpaceProgram is provided
---

## 2026-02-08 - US-404
- What was implemented: SpaceAssembler service in `cantena/services/space_assembler.py` that assembles the best possible SpaceProgram by merging geometry-detected rooms with LLM interpretation. Priority: (1) geometry rooms via `from_detected_rooms`, (2) LLM interpretation via `from_llm_interpretation`, (3) fallback via `from_building_model`. When using geometry rooms, LLM data enriches unlabeled rooms (re-classifies OTHER to specific RoomType), adds LLM-only rooms geometry missed, and flags anomalies (e.g., WC > 150 SF). `reconcile_areas()` adds explicit "Unaccounted" OTHER space for area gaps without scaling existing rooms.
- Files changed:
  - `backend/cantena/services/space_assembler.py` — new module: `SpaceAssembler` class with `assemble()`, `reconcile_areas()`, `_enrich_with_llm()` static method; `_flag_anomalies()` module-level helper for oversized WC/bathroom detection
  - `backend/tests/test_space_assembler.py` — 12 tests across 7 test classes (TestGeometryRoomsAvailable, TestNoGeometryLlmAvailable, TestNeitherAvailable, TestUnlabeledGeometryRoomsGetLlmLabels, TestAreaGapCreatesUnaccounted, TestAnomalyFlagging, TestLlmOnlyRoomsAdded)
  - `prd.json` — US-404 passes: true
- **Learnings for future iterations:**
  - Anomaly flagging should run after all SpaceProgram assembly (including LLM enrichment), not inside `_enrich_with_llm` — otherwise it's skipped when LLM data is unavailable
  - `LlmInterpretation` type in `_enrich_with_llm` parameter needs TYPE_CHECKING import (not deferred runtime import) since `from __future__ import annotations` makes annotations strings
  - Lightweight stub dataclasses in tests avoid importing heavy geometry/LLM modules — keeps test suite fast
  - `SpaceProgram.from_building_model()` uses deferred import of `get_room_costs_for_building_type` internally, so tests can call it without circular import issues
  - LLM room re-classification tries LABEL_TO_ROOM_TYPE mapping first, then RoomType(enum_value) as fallback — covers both label-based and enum-based LLM outputs
---

## 2026-02-08 - US-405
- What was implemented: Full enhanced pipeline chaining geometry room detection → LLM interpretation → SpaceProgram assembly → room-type-aware cost engine. `AnalysisPipeline` extended with optional `space_assembler: SpaceAssembler` parameter. When geometry data is available (via HybridAnalyzer), the pipeline assembles a SpaceProgram, reconciles area gaps, and passes it to CostEngine for room-type-aware pricing. `PipelineResult` extended with `space_program`, `space_breakdown`, and `room_detection_method` fields. `/api/analyze` response includes `space_breakdown` and `room_detection_method` when available. `create_pipeline()` in `deps.py` updated to wire up HybridAnalyzer + SpaceAssembler for full enhanced flow. Backward compatible: no geometry → VLM-only + `room_detection_method='assumed'`; no assembler → existing behavior unchanged.
- Files changed:
  - `backend/cantena/services/pipeline.py` — extended `PipelineResult` with 3 new fields; extended `AnalysisPipeline.__init__` with `space_assembler` param; added SpaceProgram assembly step (step 4) between hybrid analysis and cost estimation; added `_determine_room_detection_method()` static helper; graceful fallback on assembler failure
  - `backend/cantena/api/app.py` — updated `/api/analyze` response to include `space_breakdown` array and `room_detection_method` string
  - `backend/cantena/api/deps.py` — updated `create_pipeline()` to wire up `MeasurementService`, `HybridAnalyzer`, and `SpaceAssembler` for the full enhanced geometry pipeline
  - `backend/tests/test_enhanced_pipeline.py` — 8 tests across 5 test classes (TestEnhancedFlowWithGeometry: 3 tests, TestFallbackWithoutGeometry: 1 test, TestApiResponseSpaceBreakdown: 1 test, TestBackwardCompatiblePipeline: 2 tests, TestSpaceCostSourceTracking: 1 test)
  - `prd.json` — US-405 passes: true
- **Learnings for future iterations:**
  - `hybrid_result` variable must be declared as `HybridAnalysisResult | None = None` before the if/else branches to avoid NameError in the space program assembly step
  - `_determine_room_detection_method` checks `SpaceSource.GEOMETRY` vs `SpaceSource.LLM` presence in program spaces to determine detection method
  - Lightweight stub dataclasses (`_StubDetectedRoom`) reused from test_space_assembler.py pattern — avoids importing heavy geometry modules in tests
  - `SpaceAssembler` failure is caught and logged; pipeline falls back to whole-building estimate without crashing
  - `deps.py` deferred imports (VectorExtractor, MeasurementService, etc.) inside `create_pipeline()` keep module-level imports clean
---

## 2026-02-08 - US-406
- What was implemented: POST /api/estimate endpoint updated to accept optional SpaceProgram in request body. New `EstimateRequest` Pydantic model wraps `BuildingModel` + optional `SpaceProgram`. When space_program is provided, it's passed to `CostEngine.estimate()` for room-type-aware pricing and the response includes `space_breakdown` array. Without space_program, existing whole-building estimate behavior preserved.
- Files changed:
  - `backend/cantena/api/app.py` — added `EstimateRequest` model (building + optional space_program), updated `/api/estimate` endpoint to accept `EstimateRequest`, pass space_program to engine, include space_breakdown in response; added `pydantic.BaseModel` import and `SpaceProgram` import; fixed pre-existing E402 ruff errors with noqa comments
  - `backend/tests/test_estimate_endpoint.py` — new file: 6 tests across 2 test classes (TestEstimateWithSpaceProgram: 3 tests for space_breakdown in response, engine receives SpaceProgram, correct response structure; TestEstimateWithoutSpaceProgram: 3 tests for standard estimate, engine receives None, invalid data 422)
  - `backend/tests/test_api.py` — updated existing TestEstimateEndpoint to use new `{"building": ...}` request body format
  - `prd.json` — US-406 passes: true
- **Learnings for future iterations:**
  - Changing endpoint request body shape (from flat `BuildingModel` to wrapped `EstimateRequest`) requires updating all existing tests that call that endpoint
  - `EstimateRequest` Pydantic model needs runtime imports for both `BuildingModel` and `SpaceProgram` — use `# noqa: E402, TCH001` since they're after `load_dotenv` calls and used as FastAPI request body fields
  - `result.model_dump(mode="json")` already includes `space_breakdown: null` when None — the explicit `space_breakdown` key in response dict overwrites it with the detailed list when available
  - Pre-existing E402 errors in app.py (imports after load_dotenv) — fixed all three with `# noqa: E402` comments
---

